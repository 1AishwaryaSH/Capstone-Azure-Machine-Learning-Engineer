# Capstone-Azure-Machine-Learning-Engineer
This project aims at creating a machine learning customized model whose hyperparameters are tuned using HyperDrive for optimizing the pipeline and comparing the results obtained with the model constructed using Azure AutoML and deploy the best performing model. To build the pipeline we use Python SDK and a Scikit-learn model.

## Architecture
The project architecture involves the following major steps: 
script file : train.py
 * Import the dataset from the specified URL.
 * Obtain the Data.
 * Splitting the data into train and test datasets with 8:2 ratio of total available data respectively.

jupyter notebook:

* For customized model whose hyperparameters are tuned using HyperDrive
 * Creating a workspace for the pipeline.
 * Using CPU clusters if already existing or create new cluster.
 * I used Random sampling method for optimizing the hyperparameters 'C' and 'max_iter' using uniform and randint hyperdrive parameter expressions.
 * The early termination policy is BanditPolicy with an evaluation interval of 2 and slack_factor of 0.1.
 * The hyperdrive is configured using the SKLearn estimator, hyperparameter sampler, and policy.
 * Save the best model.
 * Once the run is finished I registered the best model obtained using HyperDrive.
* For AutoML model
 * we obtain a csv webfile dataset.
 * configure by setting the parameters of AutoMLConfig.
 * submit the AutoML run.
 * Obtain the metrics from the model.
 * Save the best model.
 
Compare the performance of both the models and then deploy the best model.
Once the model is deployed on the Azure Container Instance, test the model by providing sample input.
Get the log details and then delete the service. 

## Dataset
### Overview
I pass used the an open dataset from Kaggle Heart Failure Prediction
(https://www.kaggle.com/andrewmvd/heart-failure-clinical-data).
The dataset has 299 records of the patients.
### Task
 Heart failure is a common event caused by Cardiovascular diseases (CVDs) and this dataset contains 12 features that can be used to predict mortality by heart failure. 
### Access
The dataset is stored at

https://raw.githubusercontent.com/1AishwaryaSH/ML-Engineer-with-Azure-Capstone/main/heart_failure_clinical_records_dataset.csv

I imported the data into azure platform by uploading it from local files into Datasets for automated ML model whereas for tuning hyperparameters using hyperdrive I used the above mentioned link in the train.py file.
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/data1.png)

![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/data2.png)

![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/data3.png)

## Automated ML
 The model is configured with the parameters compute target and automl settings. Here the task is classification and the iterations is fixed to 30 which specifies the number of times a model is iterated to find a better accuracy metric .The primary metrics can be accuracy, AUC,.... Cross validation is used as a technique to split original data into the train and test. 
* n_cross_validations =5 parameter sets how many cross validations to perform, based on the same number of folds.
* iterations specify the total number of different algorithm and parameter combinations to test during an automated ML experiment set to 30.
* max_concurrent_iterations is 4 represents the maximum number of iterations that would be executed in parallel.
* primary_metric as Accuracy the metric that Automated Machine Learning will optimize for model selection. Automated Machine Learning collects more metrics than it can optimize.
* DEATH_EVENT is the target column.
* classification task refers to a predictive modeling problem where a class label is predicted for a given example of input data.
* experiment_timeout_minutes =30 Maximum amount of time in minutes that all iterations combined can take before the experiment terminates.
In the configuration we have compute_target is the Azure Machine Learning compute target to run the Automated Machine Learning experiment on set to the cpu_cluster we created before and the auto ml settings.
 
### Results
The AutoML model 'Voting Ensemble' gave an accuracy of 87.30%. Voting Ensemble is an ensemble model which combines multiple models to improve the final results.As we are performing the classification task this model uses the weighted average of predicted class probabilities to predict the output.

The Id for best run is: AutoML_3857386a-722a-4619-b6ff-1b5c7cb813c5_28
The Accuracy: is 0.8729943502824857

The parameters generated by the prefittedsoftvotingclassifier include: if want to validate our processing over multiple runs of the code the random state value must be the same :random_state=None,increasing this value make the model more conservative :reg_alpha=0.3157894736842105, L2 regularization term : reg_lambda=0.2631578947368421, silent=True, verbose=-10 and for robustscaler we have copy set to True, the quantile_range as [25, 75] and  with_centering enabled to True, and with_scaling enabled to False. 
Other classifiers such as extratreesclassifier, lightgbmclassifier, randomforestclassifier and so on are present.

Through the iterations the LightGBM as a base had a metric of 0.8060 that was outperformed by Voting Ensemble with 0.8730 result.

### metrics
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/metricsauto.png)
### In the Azure platform
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/automlrun1.png)
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/automlrun2.png)
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/automlrun3.png)
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/automlrun4.png)
### The run details widget
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/rundauto.png)
### The Best Model
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/bestmodelauto_azure.png)
### The registered model
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/bestmodelauto.png)

## Hyperparameter Tuning

### Algorithm
We used the Logistic regression, a supervised learning classification algorithm that does two class Binary classification to predict the discrete values {'yes' or 'no'} (1 or 0) for the column labelled 'DEATH_EVENT' in the dataset.

### Hyperparameters
The two Hyperparameters used are the 'C' or inverse regularization parameter and 'max_iter' representing the maximum number of iterations that are allowed. To perform this I used RandomParameterSampler that allows to find the better values out of large space randomly with less computation power.for 'C' a uniform distribution with a minimum value of 0 and a maximum value of 1, and for "max_iter" a random integer from 0 to 150.

### Parameter sampler
I used the RandomParameterSampler as it can be used for the early termination of the low-performance runs and also to find better metrics that could help to refine the search space. The Random Search for parameters can get good results with less amount of time.

### Policy
An early termination policy can be used to terminate the poorly performing runs. Thus improves the computational efficiency.I used BanditPolicy with an evaluation interval and slack factor.Here the evaluation interval specifies the frequency of applying the policy which is 2.The runs whose best metric is less than (primary metric of best performing run at given interval/(1+slack factor))
will be terminated. Here the slack factor taken is '0.1'.
### Run Details widget
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/rundHyper.png)
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/accuracyHyper.png)
### Results
The Id for best run is: HD_bdea9e31-d7d9-46db-9780-38b82d6cca8c_4
The Accuracy: is 0.9166666666666666
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/metricshyper.png)
### Registered model
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/besthypermodel.png)
## Experiments created
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/experiments.png)

## Comparision
In Hyperdrive I used logistic regression model for the prediction with hyperparameters namely C, max_iter, where as in AutoML multiple models were generated with less human intervention and less time which would otherwise needed more effort for tuning the hyperparameters and training these models.
For this particular project on prediction of Heart Failure the Hyperdrive pipeline is more accurate. 
The best model obtained using HyperDrive was found with an Accuracy: 0.9166666666666666 where as the best AutoMl model 'VotingEnsemble' had an Accuracy: 0.8729943502824857. So we conclude that use of AutoML. 
Coming to the aspect of execution time I found that the hyperdrive took comparitively less time to generate the model.

## Model Deployment
I deployed the Hyperdrive pipeline on Azure compute instance.
Steps to deploy:
* Define a scoring script score.py
* create an environment
     * from conda specifications in the conda_dependencies.yml file we obtained the environment for the model
* Combine scoring script & environment in Inference configuration
* Set deployment configuration with 1 cpu core, 1 GB memory
* Define the model, inference, & deployment configuration and web service name and location to deploy
* Obtain the scoring uri of the service
* to query the endpoint, I provided the data in the endpoint.py along with the scoring uri of the service
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/tree/main/screenshots/result.JPG)
* Get the logs of the service
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/webservice.png)
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/webservice2.png)
### After deleting the service
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/after%20service.delete().png)

## Future improvements
* I found that the dataset is imbalanced and further use of data cleaning techniques could help us get better accuracy models.
* We can convert the model into ONNX format .
* We can deploy the model to the Edge.
* Application insights can be enabled to monitor the deployed web service.

## ScreenCast
* https://youtu.be/o9rq82ZdgK4
## proof of clean up
### Compute Cluster
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/cluster%20delete.png)
### Compute Instance
![](https://github.com/1AishwaryaSH/Capstone-Azure-Machine-Learning-Engineer/blob/main/screenshots/instance%20delete.png)

## References
* https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-and-where?tabs=python
* https://docs.microsoft.com/en-us/azure/machine-learning/how-to-deploy-azure-container-instance
* https://docs.microsoft.com/en-us/azure/machine-learning/how-to-tune-hyperparameters
* https://docs.microsoft.com/en-us/azure/machine-learning/how-to-use-environments
